{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6bf3e46",
   "metadata": {},
   "source": [
    "you'll need to install anaconda and create an environment\n",
    "\n",
    "use of \"conda install\" for all packages installations is recommended to avoid conflicts between packages dependencies\n",
    "\n",
    "download anaconda\n",
    "https://www.anaconda.com/download\n",
    "\n",
    "managing environments\n",
    "https://conda.io/activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "from matplotlib import *\n",
    "import numpy as np\n",
    "import operator\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import linregress, spearmanr, chi2, beta\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.stats.contingency import odds_ratio\n",
    "import os, sys, re, calendar, datetime\n",
    "import subprocess\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "import os, sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e36641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to influweb files, both intake and weekly_responses datasets\n",
    "\n",
    "#v2 (namely \"22-12-1\") file path\n",
    "path='/v2'\n",
    "#v1 (namely \"21-11-1\") file path\n",
    "path_prev='/v1'\n",
    "#v0 file path\n",
    "path_prev2='/v0'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions definitions, we'll need them later\n",
    "#some basic data cleaning, homogenize answers to True and False\n",
    "\n",
    "## turn all f, FALSE to True and False\n",
    "def translate(entry):\n",
    "    if entry=='f':\n",
    "        entry=False\n",
    "    elif entry=='FALSE':\n",
    "        entry=False\n",
    "    elif entry=='t':\n",
    "        entry=True\n",
    "    elif entry=='TRUE':\n",
    "        entry=True\n",
    "    return entry\n",
    "\n",
    "## Convert weeks with formats like 2014-2 to zero-padded format 2014-02\n",
    "def fix_yearweek(date_string):\n",
    "    year, week =  map(lambda x: int(x), date_string.split('-'))\n",
    "    fixed = \"{0}-{1:02d}\".format(year, week)\n",
    "    \n",
    "    assert re.match(\"\\d{4}-\\d{2}$\", fixed)\n",
    "    return fixed\n",
    "#######################\n",
    "\n",
    "#######################\n",
    "def weekMinus(week, minusweek):\n",
    "    #week is a string 'yyyy-w'\n",
    "    yr, wk = map(lambda x: int(x), week.split('-'))\n",
    "    mid_date = getMiddleDayOfWeek(yr, wk)\n",
    "    res_date = mid_date - datetime.timedelta(days=7*minusweek)\n",
    "    isoyear, isoweek, isoday = res_date.isocalendar()\n",
    "    return str(isoyear) + '-' + str(isoweek)\n",
    "#######################\n",
    "\n",
    "#######################\n",
    "def getMiddleDayOfWeek(year, week):\n",
    "    d = datetime.date(year,1,1)\n",
    "    if(d.weekday()>3):\n",
    "        d = d+datetime.timedelta(7-d.weekday())\n",
    "    else:\n",
    "        d = d - datetime.timedelta(d.weekday())\n",
    "    dlt = datetime.timedelta(days = (week-1)*7)\n",
    "    return d + dlt + datetime.timedelta(days=3)\n",
    "#######################\n",
    "\n",
    "#######################\n",
    "def weekPlusOne(week):\n",
    "    #week is a string 'yyyy-w'\n",
    "    yr, wk = map(lambda x: int(x), week.split('-'))\n",
    "    mid_date = getMiddleDayOfWeek(yr, wk)\n",
    "    res_date = mid_date + datetime.timedelta(days=7)\n",
    "    isoyear, isoweek, isoday = res_date.isocalendar()\n",
    "    return str(isoyear) + '-' + str(isoweek)\n",
    "#######################\n",
    "\n",
    "#######################\n",
    "def days_difference(date1, date2):\n",
    "    y1,m1,d1 = map(lambda x: int(x), date1.split('-'))\n",
    "    y2,m2,d2 = map(lambda x: int(x), date2.split('-'))\n",
    "    delta_days = (datetime.date(y1,m1,d1) - datetime.date(y2,m2,d2)).days\n",
    "    return delta_days\n",
    "#######################\n",
    "\n",
    "#######################\n",
    "#define if participant is showing ILI based on declared symptoms\n",
    "def get_ILI_ECDC(row):\n",
    "    ILI=False\n",
    "    if row.Q1_0==False:\n",
    "        if row.Q5==0.0 or row.Q6b==0.0: #0 = sudden onset\n",
    "            if row.Q1_1==True or row.Q1_2==True or row.Q1_11==True or row.Q1_8==True or row.Q1_9==True:\n",
    "                if row.Q1_5==True or row.Q1_6==True or row.Q1_7==True:\n",
    "                    ILI=True  \n",
    "    return ILI\n",
    "\n",
    "#######################\n",
    "\n",
    "def get_ARI(row):\n",
    "    ARI=False\n",
    "    if row.Q1_0==False:\n",
    "        if row.Q5==0.0: #0 = sudden onset\n",
    "            if row.Q1_6==True or row.Q1_5==True or row.Q1_7==True or row.Q1_3==True:\n",
    "                ARI=True  \n",
    "    return ARI\n",
    "\n",
    "#######################\n",
    "def get_any_symp(row):\n",
    "    symp=False\n",
    "    if row.Q1_0==False:\n",
    "        symp=True  \n",
    "    return symp\n",
    "#######################\n",
    "\n",
    "def get_fever(row):\n",
    "    FEV=False\n",
    "    if row.Q1_0==False:\n",
    "        if row.Q1_1==True:\n",
    "            FEV=True  \n",
    "    return FEV\n",
    "#######################\n",
    "\n",
    "def get_phlegm(row):\n",
    "    phlegm=False\n",
    "    if row.Q1_0==False:\n",
    "        if row.Q1_7==True:\n",
    "            phlegm=True  \n",
    "    return phlegm\n",
    "\n",
    "\n",
    "#######################\n",
    "def get_onset_date( submission_date, symptoms_date, fever_date ):\n",
    "    onset_date = submission_date\n",
    "    ## if symptoms onset date is available\n",
    "    if pd.notnull(symptoms_date): \n",
    "        if 0 <= days_difference(submission_date, symptoms_date) <= 15:\n",
    "            onset_date = symptoms_date\n",
    "    ## otherwise use fever date onset. if none of them, return nan\n",
    "    elif pd.notnull(submission_date) and pd.notnull(fever_date):\n",
    "         if 0 <= days_difference(submission_date, fever_date) <= 15:\n",
    "            onset_date = fever_date    \n",
    "    return onset_date\n",
    "#######################\n",
    "\n",
    "#######################\n",
    "def get_week_of_activity(global_id, submission_weeks):\n",
    "    activity_weeks = []\n",
    "    for week in submission_weeks: \n",
    "        wk_start, wk_end = fix_yearweek(weekMinus(week, 2)), fix_yearweek(weekMinus(week, -2))\n",
    "        wk = wk_start\n",
    "        while(wk <= wk_end):\n",
    "            activity_weeks.append(wk)\n",
    "            wk = fix_yearweek(weekPlusOne(wk))\n",
    "    return sorted(set(activity_weeks))\n",
    "#######################\n",
    "\n",
    "\n",
    "###\n",
    "# Return previous week (es: lastweek(datetime.datetime.strptime('18112019', \"%d%m%Y\").date()) -> 2019-46)\n",
    "###\n",
    "def lastweek(today=date.today()):\n",
    "    for i in range(7):\n",
    "        x = str((today - timedelta(days=i)).isocalendar()[0])+'-'+str((today - timedelta(days=i)).isocalendar()[1])\n",
    "        d1 = str(today.isocalendar()[0])+'-'+str(today.isocalendar()[1])\n",
    "        if x!=d1:\n",
    "              return fix_yearweek(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336102e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Get season from week consindering the start of a new season from week week_th (int) (es: get_season_fromweek('2015-40', 45) -> 2014-2015)\n",
    "##\n",
    "def get_season_fromweek(week, week_th):\n",
    "    w_y_list = week.split('-')\n",
    "    if int(w_y_list[1]) >=week_th:         #es. week_th=45 -> new season after 45 week\n",
    "        season = str(w_y_list[0])+'-'+str(int(w_y_list[0])+1)\n",
    "    else:\n",
    "        season = str(int(w_y_list[0])-1)+'-'+str(w_y_list[0])\n",
    "    return season\n",
    "\n",
    "def week_from_date(data):\n",
    "    x = datetime.datetime.strptime(data, '%Y-%m-%d')\n",
    "    if len(str(x.isocalendar()[1]))==2:\n",
    "        w = str(x.isocalendar()[0])+'-'+str(x.isocalendar()[1])\n",
    "    else:\n",
    "        w = str(x.isocalendar()[0])+ '-0' +str(x.isocalendar()[1])\n",
    "    return w\n",
    "\n",
    "def get_epoch(x):\n",
    "    p = '%Y-%m-%d %H:%M:%S'\n",
    "    mytime = str(x)[:19]\n",
    "    epoch = datetime.datetime(1970, 1, 1)\n",
    "    tempo = int((datetime.datetime.strptime(mytime, p) - epoch).total_seconds())\n",
    "    return tempo\n",
    "\n",
    "def get_age(x):\n",
    "    subm=int(x.intake_submission[:4])\n",
    "    if any([x.version=='22-12-2', x.version=='21-11-1']):\n",
    "        new_year= int(datetime.datetime.fromtimestamp(int(x.Q2)).strftime('%Y'))\n",
    "        if subm - new_year < 0:\n",
    "            print(x.Q2)\n",
    "        return subm - new_year\n",
    "    \n",
    "    else:\n",
    "        if '/' in x.Q2 or '-' in x.Q2:\n",
    "            year=int(x.Q2[:4])\n",
    "            if subm - year < 0:\n",
    "                print(x.Q2)\n",
    "            return subm - year\n",
    "        \n",
    "## define age classes from IN data\n",
    "def get_age_class(x):\n",
    "    if x<18 and x>0:\n",
    "        return '<18'\n",
    "    elif x>=18 and x<=40:\n",
    "        return '18-40'\n",
    "    elif x>40 and x<=65:\n",
    "        return '41-65'\n",
    "    elif x>65:\n",
    "        return '>65'\n",
    "    else: return 'nan'\n",
    "    \n",
    "## extract real population pyramid from census data\n",
    "def get_iss_age_classes(x):\n",
    "    if x!='Y_GE100':\n",
    "        xx=int(x.strip('Y'))\n",
    "        if xx<=18:\n",
    "            y='<18'\n",
    "        elif xx>18 and xx<=40: #maybe 44 is the standard\n",
    "            y='18-40'\n",
    "        elif xx>40 and xx<=65:\n",
    "            y='41-65'\n",
    "        elif xx>65:\n",
    "            y='>65'\n",
    "        else:\n",
    "            y='rest'\n",
    "        return y\n",
    "    else: return 'rest'\n",
    "\n",
    "def occupation(x):\n",
    "    if str(x)!='nan':\n",
    "        x=int(x)\n",
    "        if x==0:\n",
    "            return 'full_time'\n",
    "        elif x==1:\n",
    "            return 'part_time'\n",
    "        elif x==2:\n",
    "            return 'self-employed'\n",
    "        elif x==3:\n",
    "            return 'student'\n",
    "        elif x==4:\n",
    "            return 'homemaker'\n",
    "        elif x==5:\n",
    "            return 'unemployed'\n",
    "        elif x==6:\n",
    "            return 'on leave'\n",
    "        elif x==7:\n",
    "            return 'retired'\n",
    "        elif x==8:\n",
    "            return 'other'\n",
    "    \n",
    "def schooling(x):\n",
    "    if x==0:\n",
    "        return 'none'\n",
    "    elif x==1:\n",
    "        return 'int_school'\n",
    "    elif x==2:\n",
    "        return 'high_school'\n",
    "    elif x==3:\n",
    "        return 'bachelor'\n",
    "    elif x==4:\n",
    "        return 'master_phd'\n",
    "    elif x==5:\n",
    "        return 'student'\n",
    "    \n",
    "def unite(x):\n",
    "    #print(x)\n",
    "    aa=np.where(x)[0]\n",
    "    if len(aa)>0:\n",
    "        return int(aa[0])\n",
    "        print(aa)\n",
    "    else: return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c817c6",
   "metadata": {},
   "source": [
    "### Define season and previous season one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = datetime.date.today()\n",
    "last_week = lastweek(dates)\n",
    "print(f\"Last week is: {last_week}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3749ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'Italy'\n",
    "country_code = 'IT'\n",
    "rescaling = 1000. #applies to incidence\n",
    "YEAR_MIN, YEAR_MAX = 2011, 2024 #\n",
    "\n",
    "dates = datetime.date.today()\n",
    "\n",
    "last_week = lastweek(dates)\n",
    "print(f\"Computing incidence for week: {last_week}\")\n",
    "\n",
    "my_season = get_season_fromweek(last_week, 46)\n",
    "print(f\"Computing incidence for season: {my_season}\")\n",
    "\n",
    "my_yearweek = last_week\n",
    "#############\n",
    "\n",
    "# influenza seasons go from Nov 1st to May 1st\n",
    "min_year = str(YEAR_MIN)\n",
    "max_year = str(YEAR_MAX)\n",
    "previous_season = str(int(min_year)-1)+'-'+str(int(max_year)-1)\n",
    "first_day = min_year+'-11-01' # from Nov 1stM\n",
    "last_day = max_year+'-05-01' # to May 1st\n",
    "print(f\"Min year: {min_year}, Max year: {max_year}, Prev season: {previous_season}\")\n",
    "print(f\"First day: {first_day}, Last day: {last_day}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALENDAR\n",
    "delta = datetime.timedelta(days=1)\n",
    "curr, end = datetime.date(YEAR_MIN, 1, 1), datetime.date(YEAR_MAX, 1, 1)\n",
    "date_week = dict()\n",
    "llyearweek, week_to_consider = [], []\n",
    "while curr <= end:\n",
    "    yearweek = fix_yearweek( str(curr.isocalendar()[0])+'-'+str(curr.isocalendar()[1]) )\n",
    "    date = curr.isoformat()\n",
    "    date_week[date] = yearweek\n",
    "    curr+=delta\n",
    "\n",
    "#associate each date to a season\n",
    "date_season = dict()\n",
    "season_week = defaultdict(set)\n",
    "week_season = {}\n",
    "for yr_min in range(YEAR_MIN, YEAR_MAX, 1):\n",
    "    yr_max = yr_min+1\n",
    "    for date in date_week.keys():\n",
    "        from_ = datetime.date(yr_min, 11, 1).isoformat()\n",
    "        to_ = datetime.date(yr_max, 5, 1).isoformat()\n",
    "        if str(yr_min)+'-11-01'<= date <= str(yr_max)+'-05-01' :\n",
    "            season = str(yr_min)+'-'+str(yr_max)\n",
    "            date_season[date] = season\n",
    "            date_f = datetime.datetime.strptime(str(date),'%Y-%m-%d')\n",
    "            weeknr=str(date_f.isocalendar().year)+'-'+str(date_f.isocalendar().week).zfill(2)\n",
    "            season_week[season].add(weeknr)\n",
    "            week_season[weeknr]=season\n",
    "\n",
    "#############\n",
    "\n",
    "seasons = set(season_week.keys())\n",
    "seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2\n",
    "intake_file = path+\"/intake_responses_v2.csv\"\n",
    "weekly_file = path+\"/weekly_responses_v2.csv\"\n",
    "#v1\n",
    "intake_file_prev = path_prev+\"/intake_responses_v1.csv\"\n",
    "weekly_file_prev = path_prev+\"/weekly_responses_v1.csv\"\n",
    "#v0\n",
    "intake_file_prev2 = path_prev2+\"/intake_responses_v0.csv\"\n",
    "weekly_file_prev2 = path_prev2+\"/weekly_responses_v0.csv\"\n",
    "            \n",
    "#############\n",
    "\n",
    "############\n",
    "## INTAKE ##\n",
    "############\n",
    "\n",
    "#intake v2\n",
    "intake_complete_now = pd.read_csv(intake_file, sep=',', dtype=str)\n",
    "#intake v1\n",
    "intake_complete_prev = pd.read_csv(intake_file_prev, sep=',', dtype=str)\n",
    "#intake v0\n",
    "intake_complete_prev2 = pd.read_csv(intake_file_prev2, sep=',', dtype=str)\n",
    "\n",
    "#the old platform intake survey uses a different format of timestamp, homogenize it to the new ones\n",
    "intake_complete_prev2['timestamp']=intake_complete_prev2['timestamp'].apply(lambda x: get_epoch(x))\n",
    "#this creates the column \"timestamp\" using the pre-defined function get_epoch (top of the notebook)\n",
    "#apply + lambda function work row-wise on the dataframe\n",
    "\n",
    "#merge all the versions intakes together\n",
    "intake_complete=pd.concat([intake_complete_now,intake_complete_prev,intake_complete_prev2])\n",
    "#transform the timestamp to dates\n",
    "intake_complete.timestamp = intake_complete.timestamp.apply(lambda d: pd.to_datetime(int(d),unit='s'))\n",
    "#impose a specific date format\n",
    "intake_complete.timestamp = pd.to_datetime(intake_complete.timestamp, utc=True).apply(lambda d: d.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "#sort by date\n",
    "intake_complete = intake_complete.sort_values(\"timestamp\", ascending=True)\n",
    "\n",
    "#country check to remove inconsistencies\n",
    "if 'country' in intake_complete.columns:\n",
    "    intake_complete = intake_complete[intake_complete.country == country_code]\n",
    "\n",
    "    \n",
    "# some cleaning:\n",
    "# remove surveys with no global_id , if any\n",
    "intake_complete = intake_complete[pd.isnull(intake_complete.global_id)==False]\n",
    "\n",
    "# rename cols\n",
    "intake_complete.rename(columns={'timestamp':'intake_timestamp', 'Q3':'postal_code'}, inplace=True)\n",
    "#remove eventual double submissions of the same intake survey from the same user (intake timestamp includes seconds)\n",
    "intake_complete.drop_duplicates('intake_timestamp', keep='last', inplace=True)\n",
    "\n",
    "# add date, province and vaccine\n",
    "# insert is an analogous method of column creation without calling the = operator with apply + lambda function\n",
    "# this creates the column intake_submission on the 4th column following the rule on the right \n",
    "intake_complete.insert(4, \"intake_submission\", intake_complete.intake_timestamp.str.split().str[0])\n",
    "\n",
    "#this questions in the \"intake survey\" up to v1 included, from v2 on it is in the \"vaccination\" survey\n",
    "intake_complete['vaccine'] = intake_complete.apply(lambda row: True if row['Q10']==0 else ( False if row['Q10']==1 else 'NN'), axis=1)\n",
    "intake_complete['vaccine'] = intake_complete['Q10']\n",
    "\n",
    "# add occupation and education degree\n",
    "intake_complete[['Q4','Q4d_0','Q4d_1','Q4d_2','Q4d_3','Q4d_4','Q4d_5']] = intake_complete[['Q4','Q4d_0','Q4d_1','Q4d_2','Q4d_3','Q4d_4','Q4d_5']].applymap(lambda x: translate(x))\n",
    "intake_complete['occupation'] = intake_complete['Q4'].apply(lambda x: occupation(x))\n",
    "intake_complete['education'] = intake_complete[['Q4d_0','Q4d_1','Q4d_2','Q4d_3','Q4d_4','Q4d_5']].apply(lambda x: unite(x),axis=1)\n",
    "intake_complete['education'] = intake_complete['education'].apply(lambda x: schooling(x))\n",
    "\n",
    "# add medical conditions\n",
    "intake_complete[['Q11_0','Q11_1','Q11_2','Q11_3','Q11_4','Q11_5','Q11_6','Q11_7', 'Q14_1','Q14_2','Q14_3','Q14_4','Q14_5']] = intake_complete[['Q11_0','Q11_1','Q11_2','Q11_3','Q11_4','Q11_5','Q11_6','Q11_7','Q14_1','Q14_2','Q14_3','Q14_4','Q14_5']].applymap(lambda x: translate(x))\n",
    "intake_complete[['Q12', 'Q13']] = intake_complete[['Q12', 'Q13']].astype(float)\n",
    "intake_complete[['Q1']] = intake_complete[['Q1']].astype(float)\n",
    "intake_complete[['Q2']] = intake_complete[['Q2']].astype(str)\n",
    "\n",
    "# conditions\n",
    "intake_complete['meds'] = intake_complete.apply(lambda row: True if any([row['Q11_1']==True,row['Q11_2']==True,row['Q11_3']==True,row['Q11_4']==True,row['Q11_5']==True,row['Q11_6']==True]) else False, axis=1)\n",
    "intake_complete['pregnancy'] = intake_complete.apply(lambda row: True if row['Q12']==0  else False, axis=1)\n",
    "intake_complete['smoke'] = intake_complete.apply(lambda row: True if any([row['Q13']==1,row['Q13']==2,row['Q13']==3,row['Q13']==5]) else False, axis=1)\n",
    "intake_complete['allergy'] = intake_complete.apply(lambda row: True if any([row['Q14_1']==True,row['Q14_2']==True,row['Q14_3']==True,row['Q14_4']==True]) else False, axis=1)\n",
    "intake_complete['gender'] = intake_complete.apply(lambda row: 'M' if row['Q1']==0 else 'F' if row['Q1']==1 else False, axis=1)\n",
    "intake_complete['age'] = intake_complete.apply(lambda x: get_age(x),axis=1)\n",
    "intake_complete['age_class'] = intake_complete[['age']].applymap(lambda x: get_age_class(x))\n",
    "intake_complete = intake_complete[intake_complete.age_class!='nan']\n",
    "\n",
    "intake = intake_complete[[\"global_id\",\"intake_timestamp\",\"intake_submission\",\"meds\",\"pregnancy\",\"smoke\",\"allergy\",\"gender\",\"age_class\",\"occupation\",\"education\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56cf78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize resulting dataframe first five rows\n",
    "print(intake.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec284c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## WEEKLY ##\n",
    "############\n",
    "#v2 weekly survey \n",
    "weekly_complete_now = pd.read_csv(weekly_file, sep=',', dtype=str)         #dates in timestamp\n",
    "#v1 weekly survey \n",
    "weekly_complete_prev = pd.read_csv(weekly_file_prev, sep=',', dtype=str)   #dates in timestamp\n",
    "#v0 weekly survey \n",
    "weekly_complete_prev2 = pd.read_csv(weekly_file_prev2, sep=',', dtype=str) #dates in epoch time\n",
    "#the old platform weekly results consider a different format of timestamp, homogenize it to the new ones\n",
    "weekly_complete_prev2['timestamp']=weekly_complete_prev2['timestamp'].apply(lambda x: get_epoch(x)) #conver to dates\n",
    "\n",
    "def transf_date(x):\n",
    "    if pd.notnull(x):\n",
    "        newx = pd.to_datetime(int(x),unit='s')\n",
    "        return newx\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "#transform onset, fever and end of symptoms epoch times to datetime, adding NaN where unavailable  \n",
    "weekly_complete_prev['Q3_0_open'] = weekly_complete_prev['Q3_0_open'].apply(lambda d: transf_date(d))\n",
    "weekly_complete_prev['Q4_0_open'] = weekly_complete_prev['Q4_0_open'].apply(lambda d: transf_date(d))\n",
    "weekly_complete_prev['Q6_1_open'] = weekly_complete_prev['Q6_1_open'].apply(lambda d: transf_date(d))\n",
    "weekly_complete_now['Q3_0_open'] = weekly_complete_now['Q3_0_open'].apply(lambda d: transf_date(d))\n",
    "weekly_complete_now['Q4_0_open'] = weekly_complete_now['Q4_0_open'].apply(lambda d: transf_date(d))\n",
    "weekly_complete_now['Q6_1_open'] = weekly_complete_now['Q6_1_open'].apply(lambda d: transf_date(d))\n",
    "\n",
    "#merge all versions\n",
    "weekly_complete=pd.concat([weekly_complete_now,weekly_complete_prev,weekly_complete_prev2])\n",
    "#submission epoch time to datetimes\n",
    "weekly_complete.timestamp = weekly_complete.timestamp.apply(lambda d: pd.to_datetime(int(d),unit='s', errors = 'coerce'))\n",
    "#format submission datetime dates to desired format\n",
    "weekly_complete.timestamp = pd.to_datetime(weekly_complete.timestamp, utc=True).apply(lambda d: d.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "#sort dates\n",
    "weekly_complete = weekly_complete.sort_values(\"timestamp\", ascending=True)\n",
    "#remove those not complying with format\n",
    "weekly_complete = weekly_complete[weekly_complete.timestamp <= dates.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "\n",
    "#apply same format for other answers with dates\n",
    "weekly_complete['Q3_0_open'] = pd.to_datetime(weekly_complete['Q3_0_open'], utc=True, errors='coerce').apply(lambda d: d.strftime('%Y-%m-%d'))\n",
    "weekly_complete['Q4_0_open'] = pd.to_datetime(weekly_complete['Q4_0_open'], utc=True, errors='coerce').apply(lambda d: d.strftime('%Y-%m-%d'))\n",
    "weekly_complete['Q6_1_open'] = pd.to_datetime(weekly_complete['Q6_1_open'], utc=True, errors='coerce').apply(lambda d: d.strftime('%Y-%m-%d'))\n",
    "\n",
    "#homogenize true and false in symptoms answers\n",
    "weekly_complete[['Q1_0','Q1_1','Q1_2','Q1_11','Q1_8','Q1_9','Q1_5','Q1_6','Q1_7','Q1_15','Q1_16','Q1_17','Q1_20']]= weekly_complete[['Q1_0','Q1_1','Q1_2','Q1_11','Q1_8','Q1_9','Q1_5','Q1_6','Q1_7','Q1_15','Q1_16','Q1_17','Q1_20']].applymap(lambda x: translate(x))\n",
    "weekly_complete[['Q1_21', 'Q1_23']] = weekly_complete[['Q1_21', 'Q1_23']].applymap(lambda x: translate(x))\n",
    "#same for questions on healthcare seeking \n",
    "weekly_complete[['Q7_1','Q7_2','Q7_3','Q7_4','Q8_1','Q8_2','Q8_3','Q8_4','Q8_5']]= weekly_complete[['Q7_1','Q7_2','Q7_3','Q7_4','Q8_1','Q8_2','Q8_3','Q8_4','Q8_5']].applymap(lambda x: translate(x))\n",
    "\n",
    "\n",
    "weekly_complete[['Q5', 'Q6b']] = weekly_complete[['Q5', 'Q6b']].astype(float)\n",
    "weekly_complete[['Q11']] = weekly_complete[['Q11']].astype(float)\n",
    "\n",
    "#homogeneize covid testing questions\n",
    "weekly_complete[['Qcov16_1', 'Qcov16_2', 'Qcov16_5']] = weekly_complete[['Qcov16_1', 'Qcov16_2', 'Qcov16_5']].applymap(lambda x: translate(x))\n",
    "\n",
    "# some cleaning:\n",
    "# remove surveys with no global_id, if any, and consider only surveys which have a corresponding intake survey\n",
    "weekly_complete = weekly_complete[pd.isnull(weekly_complete.global_id)==False]\n",
    "weekly_complete = weekly_complete[weekly_complete.global_id.isin(intake.global_id.unique())]\n",
    "\n",
    "# add cols\n",
    "weekly_complete.rename(columns={'timestamp': 'weekly_timestamp'}, inplace=True)\n",
    "weekly_complete.insert(3, \"submission_date\", weekly_complete.weekly_timestamp.str.split().str[0])\n",
    "weekly_complete.insert(4, \"submission_week\", weekly_complete.submission_date.map(date_week))\n",
    "weekly_complete.insert(5, \"season\", weekly_complete.submission_date.map(date_season))\n",
    "\n",
    "# consider only data for the seasons given in input \n",
    "weekly = weekly_complete[ weekly_complete.season.isin(seasons) ]\n",
    "        \n",
    "# remove duplicates within the same week, keeping the last one (user may have updated their symptoms)\n",
    "weekly = weekly_complete.drop_duplicates(['global_id','submission_week'], keep='last', inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffb359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## WEEKLY + INTAKE ##\n",
    "#####################\n",
    "# Merge weekly and intake according to the most recent intake per each weekly_survey submitted\n",
    "frames = []\n",
    "for item, group in weekly.groupby([\"global_id\",\"weekly_timestamp\",\"submission_date\"]):\n",
    "    global_id, weekly_timestamp, submission_date = item\n",
    "    #for each user consider the most recent intake submission with respect to each weekly survey submission (medical conditions, age, etc may change)\n",
    "    intake_timestamp = intake[(intake.global_id==global_id) & (intake.intake_timestamp<=weekly_timestamp)].intake_timestamp.max()\n",
    "    frames.append({'global_id': global_id, 'submission_date':submission_date, 'intake_timestamp':intake_timestamp})\n",
    "data = weekly.merge(pd.DataFrame(frames), on=[\"global_id\", \"submission_date\"], how=\"left\")\n",
    "data = data.merge(intake, on=[\"global_id\", \"intake_timestamp\"], how=\"left\")\n",
    "assert(data.shape[0]==weekly.shape[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c3cef",
   "metadata": {},
   "source": [
    "### get age-classes populations from census\n",
    "http://dati.istat.it/Index.aspx?QueryId=42869#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "age_pop=pd.read_csv('../schools_int_mobility/DCIS_POPRES1_31082023121420138.csv')\n",
    "age_pop=age_pop[age_pop.ETA1!='TOTAL']\n",
    "age_pop=age_pop[age_pop.Territorio=='Italia']\n",
    "age_pop=age_pop[age_pop.Sesso=='totale']\n",
    "\n",
    "age_pop['age_class'] = age_pop.ETA1.apply(lambda x: get_iss_age_classes(x))\n",
    "ita_pop=58850717\n",
    "age_class_pop=age_pop[['age_class','Value']].groupby('age_class')['Value'].sum()/ita_pop\n",
    "print( sum(age_class_pop) == 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTIVE USERS inclusion criteria:\n",
    "# - AT LEAST 2 symptoms surveys\n",
    "# - we count users as active from: +/- 2 weeks around the week of symptoms reporting\n",
    "\n",
    "# keep only surveys of participants who submitted >= 2 symptoms surveys\n",
    "data = data.groupby('global_id').filter(lambda x: len(x)>1)\n",
    "if data.empty:\n",
    "    sys.exit('### no active users ###\\n')\n",
    "\n",
    "# get num. of active users per week\n",
    "weekly_active_user = {}\n",
    "weekly_active_user_age_list = defaultdict(list)\n",
    "for global_id, group in data.groupby('global_id'):\n",
    "    #this counts the +/- 2 weeks around the submitted sympotms date\n",
    "    activity_weeks = get_week_of_activity(global_id, group.submission_week)\n",
    "    age=group.age_class.unique()[0]\n",
    "    #consider users with valid dates\n",
    "    if str(age)!='nan': \n",
    "        for wk in activity_weeks:\n",
    "            weekly_active_user.setdefault(wk, 0)\n",
    "            weekly_active_user[wk] += 1 #sum weekly active users as those posting in\n",
    "            weekly_active_user_age_list[wk].append(age) #count how many users we have per age class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the age correction factors, observed vs expected age class composition from census\n",
    "weekly_active_user_age_correction = defaultdict(dict)\n",
    "\n",
    "for wk in weekly_active_user_age_list:\n",
    "    age_counter=Counter(weekly_active_user_age_list[wk])\n",
    "    for age in age_counter:\n",
    "        weekly_active_user_age_correction[wk][age] = (age_counter[age]/weekly_active_user[wk]) / age_class_pop[age]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ILI cases inclusion criteria:\n",
    "# - get ILI among active users\n",
    "# - EXCLUSION OF FIRST ILI EPISODE if reported in the 1st symptoms survey of the season\n",
    "# - onset of ILI is symptoms_onset if reported and not older than 15 days\n",
    "# - keep only 1st episode if the participants reported prolonged ILI status with the same onset_week\n",
    "\n",
    "# define first_survey\n",
    "data['first_survey'] = data.groupby(['global_id'])['submission_week'].transform(np.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c9789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_ILI = data.copy(deep=True)\n",
    "\n",
    "## !!! python warning\n",
    "## data.copy(deep=True) allows to create a deep copy of the dataframe \n",
    "## setting new_df = data (without the deep copy approach) creates a new dataframe \"new_df\":\n",
    "## when you modify new_df, changes will apply on the old dataframe \"data\" as well\n",
    "## setting new_df = data.copy(deep==True) prevents this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c42ea8b",
   "metadata": {},
   "source": [
    "### only ILI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ILI = data_ILI[ data_ILI.season.isin(seasons) ] #get only weeks in seasons\n",
    "\n",
    "ILI_weeks=set(data_ILI.submission_week)\n",
    "#influenza season weeks\n",
    "submission_weeks=[x for x in list(week_season.keys()) if x<=last_week] \n",
    "#full year weeks\n",
    "submission_weeks_complete=set(data.submission_week) \n",
    "\n",
    "#create column ILI\n",
    "data_ILI['ILI'] = data_ILI.apply(lambda row: get_ILI_ECDC(row), axis=1)\n",
    "\n",
    "data_ILI['phlegm'] = data_ILI.apply(lambda row: get_phlegm(row), axis=1)\n",
    "data_ILI['fever'] = data_ILI.apply(lambda row: get_fever(row), axis=1)\n",
    "\n",
    "\n",
    "#remove first symptomatic submission ever\n",
    "data_ILI.loc[(data_ILI['ILI']==True) & (data_ILI['submission_week']==data_ILI['first_survey']), 'ILI']= False\n",
    "#define onset week (if submitted, else use fever data, else nan)\n",
    "data_ILI['onset_week'] = data_ILI.apply(lambda row: get_onset_date(row.submission_date, row['Q3_0_open'], row['Q6_1_open']) if row['ILI']==True else np.nan, axis=1).map(date_week) # only if ILI\n",
    "\n",
    "# check for multiple episodes in the same onset week\n",
    "if data_ILI[data_ILI['ILI']==True].shape[0]>0:\n",
    "    tmp = data_ILI[data_ILI.ILI==True].groupby(['global_id','onset_week'])['submission_week'].unique().reset_index(name='submission_weeks')\n",
    "    tmp['count'] = tmp['submission_weeks'].apply(lambda x: len(x))\n",
    "    # keep only the 1st episode if symptoms continue in the next weeks:\n",
    "    for global_id, onset_week, these_submission_weeks in tmp[tmp['count']>1][['global_id','onset_week','submission_weeks']].values:\n",
    "        first_episode = np.min(these_submission_weeks)\n",
    "        for wk in these_submission_weeks:\n",
    "            if wk!=first_episode:\n",
    "                data_ILI.loc[((data_ILI.global_id==global_id) & (data_ILI.submission_week==wk) & (data_ILI.ILI==True) & (data_ILI.onset_week==onset_week)), 'ILI'] = False # then turn ILI to False\n",
    "                #debug check, if none appear, there may NaNs in the onset and submission week columns\n",
    "                print('removed 1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df46bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute ILI incidence\n",
    "\n",
    "active, ILI = 0, 0\n",
    "incidence = {}\n",
    "act_threshold = 100 #(optional) minimum number of weekly active users to compute incidence\n",
    "\n",
    "for week in sorted(submission_weeks):\n",
    "    active, ILI = 0, 0\n",
    "    if week in weekly_ILI:\n",
    "        active = weekly_active_user[week]\n",
    "        ILI = weekly_ILI[week]\n",
    "    else: ILI = 0\n",
    "    if active>act_threshold and ILI>0:\n",
    "        incidence[week] = round( ILI*1.0/active*rescaling, 2 )\n",
    "    else: incidence[week] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define health seeking column\n",
    "#creates column medical_service if any of the conditions on the right if fulfilled, else False\n",
    "data_ILI[\"medical_service\"] = data_ILI.apply(lambda row: True if row['Q7_1']==True or row['Q7_2']==True or row['Q7_3']==True or row['Q7_4']==True or row['Q8_1']==True or row['Q8_2']==True or row['Q8_3']==True or row['Q8_4']==True or row['Q8_5']==True else False, axis=1)\n",
    "#apply + lambda function work row-wise, axis=1 tells the lambda function that Q7_1 etc are columns names\n",
    "\n",
    "#other examples\n",
    "data_ILI[\"medical_service_inperson\"] = data_ILI.apply(lambda row: True if row['Q7_1']==True or row['Q7_2']==True or row['Q7_3']==True or row['Q7_4']==True else False, axis=1)\n",
    "data_ILI[\"medical_service_remote\"] = data_ILI.apply(lambda row: True if row['Q8_1']==True or row['Q8_2']==True or row['Q8_3']==True or row['Q8_4']==True or row['Q8_5']==True else False, axis=1)\n",
    "data_ILI[\"flu_test\"] = data_ILI.apply(lambda row: True if row['Qcov19']=='1' else False, axis=1)\n",
    "data_ILI[\"cov_test\"] = data_ILI.apply(lambda row: True if row['Qcov16h']=='1' or row['Qcov16_1']==True or row['Qcov16_2']==True or row['Qcov16_5']==True else False, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2236aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count seasonal healthseeking behavior\n",
    "#the row below reads as: \n",
    "#get all data_ILI entries that fulfill the condition  ILI==True and then group them by season and count how many they are\n",
    "season_ILI = data_ILI[(data_ILI.ILI==True)].groupby('season').size()\n",
    "#result is the number of ILI episodes in each season\n",
    "#note that we kept one ILI episode per user per onset week(the 1st one)\n",
    "#this count should change if we want to keep more ILI reports after the 1st week of submission\n",
    "\n",
    "#same here but with two conditions\n",
    "season_ILIfever = data_ILI[(data_ILI.ILI==True)&(data_ILI.fever==True)].groupby('season').size()\n",
    "season_ILInofever = data_ILI[(data_ILI.ILI==True)&(data_ILI.fever==False)].groupby('season').size()\n",
    "season_ILIfever_phlegm = data_ILI[(data_ILI.ILI==True)&(data_ILI.fever==True)&(data_ILI.phlegm==True)].groupby('season').size()\n",
    "    \n",
    "#this is pretty much what you need to know on how python and pandas work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_ILI = data_ILI[(data_ILI.ILI==True)].groupby('onset_week').size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
